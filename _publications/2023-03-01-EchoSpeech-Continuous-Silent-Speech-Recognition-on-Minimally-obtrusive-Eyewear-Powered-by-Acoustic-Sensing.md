---
title: "EchoSpeech: Continuous Silent Speech Recognition on Minimally-obtrusive Eyewear Powered by Acoustic Sensing"
collection: publications
permalink: /publication/2023-03-01-EchoSpeech-Continuous-Silent-Speech-Recognition-on-Minimally-obtrusive-Eyewear-Powered-by-Acoustic-Sensing
excerpt: 'April 23–28, 2023, Hamburg, Germany. Keyword: Silent Speech Recognition, Acoustic Sensing, Smart Glasses'
date: 2023-03-01
venue: 'The Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI)'
paperurl: 'https://doi.org/10.1145/3544548.3580801'
citation: 'Ruidong Zhang, <u>Ke Li</u>, Yihong Hao, Yufan Wang, Zhengnan Lai, François Guimbretière, and Cheng Zhang. 2023. EchoSpeech: Continuous Silent Speech Recognition on Minimally-obtrusive Eyewear Powered by Acoustic Sensing. In <i>Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI)</i>. Association for Computing Machinery, New York, NY, USA, Article 852, 1–18.'
---
Selected Media Coverage: [Cornell Chronicle](https://news.cornell.edu/stories/2023/04/ai-equipped-eyeglasses-can-read-silent-speech), [Engadget](https://www.engadget.com/researchers-built-sonar-glasses-that-track-facial-movements-for-silent-communication-171508573.html)

April 23–28, 2023, Hamburg, Germany  
Keyword: Silent Speech Recognition, Acoustic Sensing, Smart Glasses

<figure>
    <center><img src="https://keli97.github.io/files/echospeech.png" alt="Trulli" style="width:80%" class="center"></center>
</figure>

We present EchoSpeech, a minimally-obtrusive silent speech interface (SSI) powered by low-power active acoustic sensing. EchoSpeech uses speakers and microphones mounted on a glass-frame and emits inaudible sound waves towards the skin. By analyzing echos from multiple paths, EchoSpeech captures subtle skin deformations caused by silent utterances and uses them to infer silent speech. With a user study of 12 participants, we demonstrate that EchoSpeech can recognize 31 isolated commands and 3-6 figure connected digits with 4.5% (std 3.5%) and 6.1% (std 4.2%) Word Error Rate (WER), respectively. We further evaluated EchoSpeech under scenarios including walking and noise injection to test its robustness. We then demonstrated using EchoSpeech in demo applications in real-time operating at 73.3mW, where the real-time pipeline was implemented on a smartphone with only 1-6 minutes of training data. We believe that EchoSpeech takes a solid step towards minimally-obtrusive wearable SSI for real-life deployment.

<iframe width="420" height="315"
src="https://www.youtube.com/embed/ZjucAwFqVqQ">
</iframe>

<!--Recommended citation: Ruidong Zhang, <u>Ke Li</u>, Yihong Hao, Yufan Wang, Zhengnan Lai, François Guimbretière, and Cheng Zhang. 2023. EchoSpeech: Continuous Silent Speech Recognition on Minimally-obtrusive Eyewear Powered by Acoustic Sensing. In <i>Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI ’23), April 23–28, 2023, Hamburg, Germany</i>. ACM, New York, NY, USA, 18 pages.-->
