---
title: "EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband"
collection: publications
permalink: /publication/2024-01-18-EchoWrist-Continuous-Hand-Pose-Tracking-and-Hand-Object-Interaction-Recognition-Using-Low-Power-Active-Acoustic-Sensing-On-a-Wristband
excerpt: 'May 11-16, 2024, Honolulu, Hawaiʻi, USA. Keyword: Acoustic Sensing, Smartwatch'
date: 2024-01-18
venue: 'The Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI)'
paperurl: 'https://dl.acm.org/doi/10.1145/3613904.3642910'
citation: 'Chi-Jung Lee (Co-Primary), Ruidong Zhang (Co-Primary), Devansh Agarwal, Tianhong Catherine Yu, Vipin Gunda, Oliver Lopez, James Kim, Sicheng Yin, Boao Dong, <u>Ke Li</u>, Mose Sakashita, Francois Guimbretiere, and Cheng Zhang. 2024. EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband. In <i>Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI)</i>. Association for Computing Machinery, New York, NY, USA, Article 403, 1–21.'
teaser_gif: /files/pubs/echowrist.gif
---
[Video preview](https://www.youtube.com/watch?v=-2O0KfvkpvA), [Presentation video](https://www.youtube.com/watch?v=NartQ5q08_I)

Selected Media Coverage: [Cornell Chronicle](https://news.cornell.edu/stories/2024/04/wristband-uses-echos-ai-track-hand-positions-vr-and-more)

May 11-16, 2024, Honolulu, Hawaiʻi, USA<br>
Keyword: Acoustic Sensing, Smartwatch

<figure>
    <center><img src="https://keli97.github.io/files/echowrist.png" alt="Trulli" style="width:100%" class="center"></center>
</figure>

Our hands serve as a fundamental means of interaction with the world around us. Therefore, understanding hand poses and interaction context is critical for human-computer interaction. We present EchoWrist, a low-power wristband that continuously estimates 3D hand pose and recognizes hand-object interactions using active acoustic sensing. EchoWrist is equipped with two speakers emitting inaudible sound waves toward the hand. These sound waves interact with the hand and its surroundings through reflections and diffractions, carrying rich information about the hand’s shape and the objects it interacts with. The information captured by the two microphones goes through a deep learning inference system that recovers hand poses and identifies various everyday hand activities. Results from the two 12-participant user studies show that EchoWrist is effective and efficient at tracking 3D hand poses and recognizing hand-object interactions. Operating at 57.9mW, EchoWrist is able to continuously reconstruct 20 3D hand joints with MJEDE of 4.81mm and recognize 12 naturalistic hand-object interactions with 97.6% accuracy.

<iframe width="420" height="315"
src="https://www.youtube.com/embed/yCLDzKarIEo">
</iframe>
